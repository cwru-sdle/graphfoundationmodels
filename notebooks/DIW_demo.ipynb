{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Ink Write ddDT Demo\n",
    "This notebook presents an example for training a ddDT on the direct ink write advanced manufacturing exemplar.\n",
    "\n",
    "Before running this notebook, make sure the package is installed in your system by running \n",
    "`pip install -e .` from the base directory of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cpu\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from tsl.engines import Predictor\n",
    "from tsl.data import ImputationDataset\n",
    "from tsl.utils.casting import torch_to_numpy\n",
    "from tsl.ops.connectivity import adj_to_edge_index\n",
    "from tsl.metrics.torch import MaskedMSE, MaskedMAE, MaskedMAPE\n",
    "from tsl.data.preprocessing import MinMaxScaler\n",
    "from tsl.data.datamodule import SpatioTemporalDataModule, TemporalSplitter\n",
    "\n",
    "from graphfoundationmodels.models.stGAE import STConvAE\n",
    "from graphfoundationmodels.dataloaders.dataloader_DIW import DIWDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "# check for GPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device used: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we will define the data loading process using the dataloader we've defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/diw-stgnn-featmat.parquet'\n",
    "\n",
    "torch_dataset = DIWDataset(target_path=DATA_PATH,eval_mask=None,\n",
    "                                  connectivity=None,\n",
    "                                  window=250,\n",
    "                                  stride=25)\n",
    "\n",
    "splitter = TemporalSplitter(val_len=0.25, test_len=0.05)\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    splitter=splitter,\n",
    "    batch_size=8,\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can define our model, importing the standard `STConvAE` from the package. We also utilize multiple metrics, such as MSE, MAE, and MAPE.\n",
    "TorchSpacialTemporal also provides us with a useful `Predictor` object to keep track of our training details, such as loss function, learning rate, and optimizer, for which we use fairly standard values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgnn = STConvAE(device=device, \n",
    "                 num_nodes=torch_dataset.n_nodes, \n",
    "                 channel_size_list=np.array([[3, 8, 16], [16, 8, 3]]), \n",
    "                 num_layers=2,\n",
    "                 kernel_size=4, \n",
    "                 K=2,\n",
    "                 kernel_size_de=2,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 normalization='sym',\n",
    "                 bias=True)\n",
    "\n",
    "loss_fn = MaskedMAE()\n",
    "\n",
    "metrics = {'mse': MaskedMSE(),\n",
    "           'mae': MaskedMAE(),\n",
    "           'mape': MaskedMAPE(),\n",
    "           }\n",
    "\n",
    "predictor = Predictor(\n",
    "    model=stgnn,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    optim_kwargs={'lr': 0.01},\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=metrics,\n",
    "    scheduler_class=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_kwargs={'step_size':15}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now begin training. We also pull in a helper callback to make some plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphfoundationmodels.util.callbacks import LossPlotCallback\n",
    "loss_plot_callback = LossPlotCallback()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1,\n",
    "                     accelerator='gpu',\n",
    "                     callbacks=[loss_plot_callback])\n",
    "\n",
    "trainer.fit(predictor, datamodule=dm)\n",
    "\n",
    "loss_plot_callback.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the model, we now predict on the test set that the model hasn't seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.freeze()\n",
    "trainer.test(predictor, datamodule=dm)\n",
    "\n",
    "# generate predictions\n",
    "output = trainer.predict(predictor, dataloaders=dm.test_dataloader())\n",
    "output = predictor.collate_prediction_outputs(output)\n",
    "output = torch_to_numpy(output)\n",
    "\n",
    "truth = output['y']\n",
    "pred = output['y_hat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize, make a scatterplot of the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = pred.shape[3]\n",
    "truth_flattened = truth.reshape(-1, num_features)\n",
    "pred_flattened = pred.reshape(-1, num_features)\n",
    "\n",
    "fig, axes = plt.subplots(1, num_features, figsize=(15, 5))\n",
    "\n",
    "feature_names = ['X-error', 'Y-error', 'Z-error']\n",
    "\n",
    "for feature_idx in range(num_features):\n",
    "    ax = axes[feature_idx]\n",
    "    ax.scatter(truth_flattened[:, feature_idx], pred_flattened[:, feature_idx], alpha=0.5, s=1)\n",
    "\n",
    "    ax.set_title(f'{feature_names[feature_idx]}')\n",
    "    ax.set_xlabel('Actual Values')\n",
    "    ax.set_ylabel('Predicted Values')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or plot reconstructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in random.sample(range(0, pred.shape[0]), 3):\n",
    "\n",
    "    node_id = random.sample(range(0, pred.shape[2]), 1)\n",
    "    feature_names = ['X-error', 'Y-error', 'Z-error']\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_features, figsize=(15, 5))\n",
    "    for feature_idx in range(num_features):\n",
    "        ax = axes[feature_idx]\n",
    "        ax.plot(truth[i, :, node_id, feature_idx][0])\n",
    "        ax.plot(pred[i, :, node_id, feature_idx][0])\n",
    "\n",
    "        ax.set_title(f'{feature_names[feature_idx]}')\n",
    "        ax.set_xlabel('Timestep')\n",
    "        ax.set_ylabel('Error')\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
